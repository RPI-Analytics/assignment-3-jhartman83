{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Python Exercises\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel → Restart) and then run all cells (in the menubar, select Cell → Run All).  You can speak with others regarding the assignment but all work must be your own. \n",
    "\n",
    "\n",
    "### This is a 30 point assignment graded from answers to questions and automated tests that should be run at the bottom. Be sure to clearly label all of your answers and commit final tests at the end. If you attempt to fake passing the tests you will receive a 0 on the assignment and it will be considered an ethical violation. (Note, not all questions have tests).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NAME = \"Jordan Hartman\"\n",
    "COLLABORATORS = [\"\"]  #You can speak with others regarding the assignment, but all typed work must be your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: 'conda-forge' already in 'channels' list, moving to the top\n"
     ]
    }
   ],
   "source": [
    "# If you have trouble loading your unittests below, \n",
    "!conda config --add channels conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching package metadata ...............\n",
      "Solving package specifications: .\n",
      "\n",
      "# All requested packages already installed.\n",
      "# packages in environment at C:\\Users\\jhpat\\Anaconda3:\n",
      "#\n",
      "ipython_unittest          0.3.1                    py36_0    conda-forge\n"
     ]
    }
   ],
   "source": [
    "!conda install --yes ipython_unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Loads a Testing Array \n",
    "- This runs tests against your b array.  If you complete the assingment correctly, you will pass the tests. \n",
    "- **If you attempt to fake passing the tests you will receive a 0 on the assignment and it will be considered an ethical violation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext ipython_unittest\n",
    "#This runs tests against your b array.  If you complete the assingment correctly, you will pass the tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises - For and If.\n",
    "\n",
    "(1). Write a program which create a list called `fivetoten` of all numbers from 5 to 10 (inclusive).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fivetoten = [5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2). Write a program which uses a for loop and if statements to create a list called `divby7` of all numbers from 1-50 that are divisible by 7.\n",
    "Hint: 14 is divisible by 7 if 14%7==0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "divby7 = 0\n",
    "for counter in range(1,50):\n",
    "    if counter%7==0:\n",
    "        divby7 =+ counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3). Write a program which uses a for loop and if statements create a list `divby7not5` of all numbers which are divisible by 7 but are not a multiple of 5, between 10000 and 10100 (both included). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "divby7not5=0\n",
    "for counter in range(10000,10100):\n",
    "    if counter%7==0 and counter%5!=0:\n",
    "        divby7not5+=counter\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises - Functions\n",
    "\n",
    "(4). Create a function `divby2` that accepts a list and returns all values from that list that are divisible by 2.  For example, passing the list  `numbers = [3, 12, 91, 33, 21, 34, 54, 34, 34, 54]` should return a list. Generate a new list `divby2` that includes only numbers that are divisible by 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divby2(list):\n",
    "    for num in list:\n",
    "        if num%2==0:\n",
    "            divby2+=num\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Execute this code to assign divby2 to the correct values. \n",
    "numbers = [3, 12, 91, 33, 21, 34, 54, 34, 34, 54]\n",
    "divby2=divby2(numbers)\n",
    "print(divby2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Create an external module for your `divby2` function called `myutilities.py`.  Import myutilities as mu, such that that following runs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#After importing this should work. (Feel free to add code to reimport)\n",
    "import myutilities as mu\n",
    "divby2mod=mu.divby2(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises-Titanic\n",
    "\n",
    "The following exercises will use the titanic data from Kaggle.  I've included it in the input folder just like Kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# Let's input them into a Pandas DataFrame\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test  = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "(6). While we can submit our answer to Kaggle to see how it will perform, we can also utilize our test data to assess accuracy. Accuracy is the percentage of predictions made correctly-i.e., the percentage of people in which our prediction regarding their survival. <br>Create columns in the training dataset `PredEveryoneDies` and `PredGender` with the same predictions which were included in the example notebook (06-intro-kaggle-baseline in the materials repository).   \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "5      0\n",
       "6      1\n",
       "7      0\n",
       "8      1\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     1\n",
       "13     0\n",
       "14     1\n",
       "15     1\n",
       "16     0\n",
       "17     0\n",
       "18     1\n",
       "19     1\n",
       "20     0\n",
       "21     0\n",
       "22     1\n",
       "23     0\n",
       "24     1\n",
       "25     0\n",
       "26     1\n",
       "27     0\n",
       "28     0\n",
       "29     0\n",
       "      ..\n",
       "388    0\n",
       "389    0\n",
       "390    0\n",
       "391    1\n",
       "392    0\n",
       "393    0\n",
       "394    0\n",
       "395    1\n",
       "396    0\n",
       "397    1\n",
       "398    0\n",
       "399    0\n",
       "400    1\n",
       "401    0\n",
       "402    1\n",
       "403    0\n",
       "404    0\n",
       "405    0\n",
       "406    0\n",
       "407    0\n",
       "408    1\n",
       "409    1\n",
       "410    1\n",
       "411    1\n",
       "412    1\n",
       "413    0\n",
       "414    1\n",
       "415    0\n",
       "416    0\n",
       "417    0\n",
       "Name: PredGender, Length: 418, dtype: int32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test  = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "test[\"EveryoneDies\"] = 0\n",
    "submission = test.loc[:,[\"PassengerId\", \"Survived\"]]\n",
    "submission.head()\n",
    "\n",
    "submission.to_csv('everyoneDies.csv', index=False)\n",
    "\n",
    "test.loc[test['Sex'] == 'male', 'PredGender'] = 0\n",
    "test.loc[test['Sex'] == 'female', 'PredGender'] = 1\n",
    "test.PredGender.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) Create variables `AccEveryoneDies` and `AccGender` using a calculation of accuracy of predictions for the `training` dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AccEveryoneDies = test.loc[:,['PassengerId', 'EveryoneDies']]\n",
    "AccGender = test.loc[:,['PassengerId', 'PredGender']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8). Notice how we are utilizing the code to select out the `passengerID` and the `Survived` column and generating a submission file over and over? This is in need of a function.  Create a `generate_submission` function that accepts a DataFrame, a target column, and a filename and writes out the submission file with just the `passengerID` and the `Survived` columns, where the survived column is equal to the target column. It should then return a DataFrame with the `passengerID` and the `Survived` columns.\n",
    "\n",
    "Executeing the following:\n",
    "`submitdie = generate_submission(train, 'PredEveryoneDies', 'submiteveryonedies.csv')`\n",
    "\n",
    "Should return a dataframe with just `passengerID` and the `Survived` column.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c393149a78e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgenerate_submission\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PredEveryoneDies'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'submiteveryonedies.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_submission(dataframe, targetcol, filename):\n",
    "    train = pd.read_csv(filename)\n",
    "    \n",
    "    \n",
    "generate_submission(train, 'PredEveryoneDies', 'submiteveryonedies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(9). In accordance to the [women and children first](https://en.wikipedia.org/wiki/Women_and_children_first) protocol, we hypothesize that our model could be improved by including whether the individual was a child in addition to gender.  *After* coding survival based on gender, update your recommendation to prediction in the training dataset survival based on age. <br> <br>\n",
    "\n",
    "In other words, your model should predict that a male child would survive.  \n",
    "\n",
    "`train['PredGenderAge13']` should be the prediction incorporating both Gender and whether Age <  13.\n",
    "`train['PredGenderAge18']` should be the prediction incorporating both Gender and whether Age <  18.\n",
    "`AccGenderAge13` should be the accuracy of the age prediction, based on `train['PredGenderAge13']`. \n",
    "`AccGenderAge18` should be the accuracy of the age prediction, based on `train['PredGenderAge18']`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10). Create a prediction file for the \"women and children first\" model in column` PredGenderAge13` and upload it to Kaggle.  Take a screen shot of your position. Put that screenshot in this repository and use markdown to show your results in the cell below.  The syntax for including a markdown picture is shown below.  \n",
    "\n",
    "```\n",
    "![]myscreenshot.png\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(11). You should find that the AccGenderAge13 is better than AccGenderAge18. Create a new column `child` in the test and train DataFrames that is 1 if Age <  13 and 0 otherwise.  This is a *feature*.  We will talk more about features next time.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Cell magic `%%unittest_main` not found.\n"
     ]
    }
   ],
   "source": [
    "%%unittest_main\n",
    "class TestExercise3(unittest.TestCase):\n",
    "    def test_forif1(self):\n",
    "        self.assertTrue(fivetoten == [5,6,7,8,9,10])\n",
    "    def test_forif2(self):\n",
    "        self.assertTrue(divby7 == [7,14,21,28,35,42,49])\n",
    "    def test_forif(self):\n",
    "        self.assertTrue(divby7not5 == [10003, 10017, 10024, 10031, 10038, 10052, 10059, 10066, 10073, 10087, 10094])\n",
    "    def test_functions(self):\n",
    "        self.assertTrue(divby2 == [12, 34, 54, 34, 34, 54])\n",
    "    def test_functions(self):\n",
    "        self.assertTrue(divby2mod == [12, 34, 54, 34, 34, 54])\n",
    "    def test_titanic1(self):\n",
    "        self.assertAlmostEqual(AccEveryoneDies, 61.6161616162)\n",
    "    def test_titanic2(self):\n",
    "        self.assertAlmostEqual(AccGender, 78.6756453423)\n",
    "    def test_titanic3(self):\n",
    "        self.assertAlmostEqual(train['PredEveryoneDies'].mean(), 0.0)\n",
    "    def test_titanic4(self):\n",
    "        self.assertAlmostEqual(train['PredGender'].mean(), 0.35241301908)\n",
    "    def test_titanic5(self):\n",
    "        self.assertTrue(['PassengerId', 'Survived']==list(pd.read_csv('submiteveryonedies.csv').columns.values))\n",
    "    def test_titanic6(self):\n",
    "        self.assertAlmostEqual(train['PredGenderAge13'].mean(), 0.393939393939)\n",
    "    def test_titanic7(self):\n",
    "        self.assertAlmostEqual(train['PredGenderAge18'].mean(), 0.417508417508)\n",
    "    def test_titanic8(self):\n",
    "        self.assertAlmostEqual(AccGenderAge13, 79.2368125701)\n",
    "    def test_titanic9(self):\n",
    "        self.assertAlmostEqual(AccGenderAge18, 77.3288439955)\n",
    "    def test_titanic10(self):\n",
    "        self.assertTrue(train['child'].sum()==69)\n",
    "    def test_titanic11(self):\n",
    "        self.assertTrue(test['child'].sum()==25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is a collection of all of the tests from the exercises above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
